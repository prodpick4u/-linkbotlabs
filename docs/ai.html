<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Puter.js AI Examples</title>
    <script src="https://js.puter.com/v2/"></script>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; background: #1a1a1a; color: #f0f0f0; }
        section { margin-bottom: 40px; padding: 20px; border: 1px solid #444; border-radius: 8px; background: #2c2c2c; }
        h2 { margin-top: 0; color: #ffcc00; }
    </style>
</head>
<body>
    <h1>Puter.js AI Code Examples</h1>

    <!-- Example 1: GPT-5 Nano Text Generation -->
    <section>
        <h2>Example 1: GPT-5 Nano Text Generation</h2>
        <script>
            puter.ai.chat("What are the benefits of exercise?", { model: "gpt-5-nano" })
                .then(response => {
                    puter.print(response);
                });
        </script>
    </section>

    <!-- Example 2: DALL·E 3 Image Generation -->
    <section>
        <h2>Example 2: DALL·E 3 Image Generation</h2>
        <script>
            puter.ai.txt2img("A futuristic cityscape at night")
                .then(imageElement => {
                    document.body.appendChild(imageElement);
                });
        </script>
    </section>

    <!-- Example 3: Analyze Images -->
    <section>
        <h2>Example 3: Image Analysis</h2>
        <script>
            puter.ai.chat(
                "What do you see in this image?", 
                "https://assets.puter.site/doge.jpeg",
                { model: "gpt-5-nano" }
            )
            .then(response => {
                puter.print(response);
            });
        </script>
    </section>

    <!-- Example 4: Use Different Models -->
    <section>
        <h2>Example 4: Multiple OpenAI Models</h2>
        <script>
            const models = ["gpt-4.1", "o3-mini", "o1-mini", "gpt-4o"];
            models.forEach(model => {
                puter.ai.chat(
                    "Write a short poem about coding",
                    { model }
                ).then(response => {
                    puter.print(`<h3>Using ${model}</h3>`);
                    puter.print(response);
                });
            });
        </script>
    </section>

    <!-- Example 5: Stream Long Responses -->
    <section>
        <h2>Example 5: Streaming Responses</h2>
        <script>
            async function streamResponse() {
                const response = await puter.ai.chat(
                    "Explain the theory of relativity in detail", 
                    {stream: true, model: "gpt-5-nano"}
                );
                for await (const part of response) {
                    puter.print(part?.text);
                }
            }
            streamResponse();
        </script>
    </section>
</body>
</html>
